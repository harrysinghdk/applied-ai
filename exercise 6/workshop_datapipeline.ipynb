{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple toy model to have something to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 16, kernel_size=3, padding=0),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(16 * 3 * 3, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the MNIST dataset<br>\n",
    "this comes with all torch niceties and helpers, but we will try to get the<br>\n",
    "raw data from here (not all the way to the file system, but close enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='../data/mnist',\n",
    "    train=True,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we extract the data from the dataset and we store it as a simple array of numbers<br>\n",
    "DO NOT DO THIS, this is just for explanation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we create some simple examples of preprocessing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_np_image_to_tensor = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((10, 10)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "transform_np_vector_to_tensor = torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "images = np.array(dataset.data)\n",
    "labels = np.array(dataset.targets)\n",
    "\n",
    "# Split into train/val (e.g., 80% train, 20% val)\n",
    "train_imgs, val_imgs, train_lbls, val_lbls = train_test_split(images, labels, test_size=0.2)\n",
    "\n",
    "# Zip them into datasets\n",
    "dataset_numpy = list(zip(train_imgs, train_lbls))\n",
    "validation_dataset = list(zip(val_imgs, val_lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(num_epoch, model, dataset, validation_dataset, loss_f, optimizer):\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for images, labels in dataset:\n",
    "            x = transform_np_image_to_tensor(images).unsqueeze(0)\n",
    "            y = transform_np_vector_to_tensor(labels).unsqueeze(0)\n",
    "\n",
    "            output = model(x)\n",
    "            loss = loss_f(output, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in validation_dataset:\n",
    "                x_val = transform_np_image_to_tensor(val_images).unsqueeze(0)\n",
    "                y_val = transform_np_vector_to_tensor(val_labels).unsqueeze(0)\n",
    "\n",
    "                out_val = model(x_val)\n",
    "                loss_val = loss_f(out_val, y_val)\n",
    "                epoch_val_loss += loss_val.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {epoch_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: Validation Loss = {epoch_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 66652.5946\n",
      "Epoch 1: Validation Loss = 15463.4850\n",
      "Epoch 2: Train Loss = 63471.1809\n",
      "Epoch 2: Validation Loss = 15814.3972\n",
      "Epoch 3: Train Loss = 63175.6020\n",
      "Epoch 3: Validation Loss = 15308.9369\n",
      "Epoch 4: Train Loss = 62932.9859\n",
      "Epoch 4: Validation Loss = 14722.3378\n",
      "Epoch 5: Train Loss = 63086.6762\n",
      "Epoch 5: Validation Loss = 15417.6743\n",
      "Epoch 6: Train Loss = 62894.6328\n",
      "Epoch 6: Validation Loss = 14823.7376\n",
      "Epoch 7: Train Loss = 62858.3646\n",
      "Epoch 7: Validation Loss = 15006.8733\n",
      "Epoch 8: Train Loss = 62846.8524\n",
      "Epoch 8: Validation Loss = 15326.1170\n",
      "Epoch 9: Train Loss = 63055.3898\n",
      "Epoch 9: Validation Loss = 15204.2783\n",
      "Epoch 10: Train Loss = 62850.0959\n",
      "Epoch 10: Validation Loss = 15528.4370\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    10,\n",
    "    model,\n",
    "    dataset_numpy,\n",
    "    validation_dataset,\n",
    "    loss_f = torch.nn.L1Loss(),\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%<br>\n",
    "additional exercise (if this is of interest to you)<br>\n",
    "based of the CelebA_Local dataset provided in the solution for exercise 4,<br>\n",
    "can you build a data pipeline yourself using torch datasets?<br>\n",
    "try to use it to do some of the tasks outlined in exercise 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
